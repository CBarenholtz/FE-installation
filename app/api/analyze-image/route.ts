import { type NextRequest, NextResponse } from "next/server"interface GroqVisionResponse {  choices: Array<{    message: {      content: string    }  }>}interface ImageAnalysisResult {  fixtureType: "tub" | "kitchen_sink" | "bathroom_sink" | "unknown"  confidence: number}export async function POST(request: NextRequest) {  try {    const { imageDataUrl } = await request.json()    if (!imageDataUrl) {      return NextResponse.json({ error: "Image data URL is required" }, { status: 400 })    }    if (!process.env.GROQ_API_KEY) {      return NextResponse.json({ error: "Groq API key not configured" }, { status: 500 })    }    console.log(" Server: Starting Groq API call...")    const requestBody = {      model: "llama-3.2-90b-vision-preview",      messages: [        {          role: "user",          content: [            {              type: "text",              text: 'Analyze this image and identify what bathroom fixture is shown. Respond with ONLY one of these exact words: "tub", "kitchen_sink", "bathroom_sink", or "unknown". Look for: bathtubs, shower areas, kitchen sinks, bathroom sinks, faucets, or plumbing fixtures.',            },            {              type: "image_url",              image_url: {                url: imageDataUrl,              },            },          ],        },      ],      max_tokens: 10,      temperature: 0.1,    }    const response = await fetch("https://api.groq.com/openai/v1/chat/completions", {      method: "POST",      headers: {        Authorization: `Bearer ${process.env.GROQ_API_KEY}`,        "Content-Type": "application/json",      },      body: JSON.stringify(requestBody),    })    if (!response.ok) {      const errorText = await response.text()      console.error(" Server: Groq API error:", errorText)      return NextResponse.json({ error: `Groq API error: ${response.status}` }, { status: 500 })    }    const data: GroqVisionResponse = await response.json()    const content = data.choices[0]?.message?.content?.toLowerCase().trim()    console.log(" Server: AI response:", content)    // Parse the response    let fixtureType: ImageAnalysisResult["fixtureType"] = "unknown"    let confidence = 0.3    if (content?.includes("tub")) {      fixtureType = "tub"      confidence = 0.8    } else if (content?.includes("kitchen_sink")) {      fixtureType = "kitchen_sink"      confidence = 0.8    } else if (content?.includes("bathroom_sink")) {      fixtureType = "bathroom_sink"      confidence = 0.8    }    return NextResponse.json({ fixtureType, confidence })  } catch (error) {    console.error(" Server: Critical error:", error)    return NextResponse.json({ error: "Internal server error" }, { status: 500 })  }}